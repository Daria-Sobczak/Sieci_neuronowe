{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA # ????\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron2(object):\n",
    "    \"\"\"Perceptron classifier.\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    eta: float \n",
    "        Learning rate (between 0.0 and 1.0)\n",
    "    n_iter: int\n",
    "        Number of epochs, i.e., passes over the training dataset.\n",
    "        \n",
    "    Attributes\n",
    "    ------------\n",
    "    w_: 1d-array\n",
    "        Weights after fitting.\n",
    "    errors_: list\n",
    "        Number of misclassifications in every epoch.\n",
    "    random_state : int\n",
    "        The seed of the pseudo random number generator.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, eta=0.01, n_iter=10, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1+X.shape[1])\n",
    "        self.errors_ = []\n",
    "        \n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0.0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (self.predict(xi) - target)\n",
    "                self.w_[1:] -= update * xi\n",
    "                self.w_[0] -= update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "    \n",
    "    def net_output(self, X):\n",
    "        \"\"\"Calculate net output\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.net_output(X) >= 0.0, 1, -1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaline(object):\n",
    "    \"\"\"ADAptive LInear NEuron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "        Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "        Passes over the training dataset.\n",
    "    random_state : int\n",
    "        The seed of the pseudo random number generator.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "        Weights after fitting.\n",
    "    errors_ : list\n",
    "        Number of misclassifications in every epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "            Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        self.cost_ = []\n",
    "\n",
    "        for i in range(self.n_iter):\n",
    "            output = self.activation(X)\n",
    "            errors = (y - output)\n",
    "            self.w_[1:] += self.eta * X.T.dot(errors)\n",
    "            self.w_[0] += self.eta * errors.sum()\n",
    "            cost = (errors**2).sum() / 2.0\n",
    "            self.cost_.append(cost)\n",
    "        return self\n",
    "\n",
    "    def net_output(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def activation(self, X):\n",
    "        \"\"\"Compute linear activation\"\"\"\n",
    "        y = self.net_output(X)\n",
    "        z = 1/(1 + np.exp(-y)) \n",
    "        return z\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.activation(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasyfikacja dla 4 cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_y(y, class_value):\n",
    "    yy = []\n",
    "    for x in y:\n",
    "        if x == class_value:\n",
    "            x = 1\n",
    "        else:\n",
    "            x = -1\n",
    "        yy.append(x)\n",
    "    y = yy\n",
    "    return y\n",
    "\n",
    "def get_data(n=4):\n",
    "    iris = datasets.load_iris()\n",
    "    X1 = iris.data[0:150, :n]\n",
    "    yy1 = iris.target[0:150]\n",
    "\n",
    "    X2 = iris.data[0:150, :n]\n",
    "    yy2 = iris.target[0:150]\n",
    "\n",
    "    X3 = iris.data[0:150, :n]\n",
    "    yy3 = iris.target[0:150]\n",
    "    \n",
    "    y1 = prepare_y(yy1, 0)\n",
    "    y2 = prepare_y(yy1, 1)\n",
    "    y3 = prepare_y(yy1, 2)\n",
    "    \n",
    "    X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=0)\n",
    "    X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=0)\n",
    "    X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=0)\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X1)\n",
    "    X1_train_std = sc.transform(X1_train)\n",
    "    X1_test_std = sc.transform(X1_test)\n",
    "\n",
    "    sc.fit(X2)\n",
    "    X2_train_std = sc.transform(X2_train)\n",
    "    X2_test_std = sc.transform(X2_test)\n",
    "\n",
    "    sc.fit(X3)\n",
    "    X3_train_std = sc.transform(X3_train)\n",
    "    X3_test_std = sc.transform(X3_test)\n",
    "    \n",
    "#     sc = StandardScaler()\n",
    "    sc.fit(X1)\n",
    "    X1_std = sc.transform(X1)\n",
    "    \n",
    "    set1 = (X1_train_std, y1_train, X1_test_std, y1_test)\n",
    "    set2 = (X2_train_std, y2_train, X2_test_std, y2_test)\n",
    "    set3 = (X3_train_std, y3_train, X3_test_std, y3_test)\n",
    "    \n",
    "    return X1_std, set1, set2, set3, yy1\n",
    "\n",
    "def test_total_performance(X, m1, m2, m3, yy1):\n",
    "    good = 0\n",
    "    a1 = np.arange(0,50)\n",
    "    a2 = np.arange(50,100)\n",
    "    a3 = np.arange(100,150)\n",
    "    ac = np.arange(0,150)\n",
    "\n",
    "\n",
    "    for a in ac:\n",
    "        y1_pred0 = m1.net_output(X[a,:])\n",
    "        y2_pred0 = m2.net_output(X[a,:])\n",
    "        y3_pred0 = m3.net_output(X[a,:])\n",
    "        if np.argmax([y1_pred0, y2_pred0, y3_pred0]) == yy1[a]:\n",
    "            good = good+1\n",
    "\n",
    "    return good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przygotowanie Danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_std, set1, set2, set3, yy1 = get_data(n=4)\n",
    "(X1_train_std, y1_train, X1_test_std, y1_test) = set1\n",
    "(X2_train_std, y2_train, X2_test_std, y2_test) = set2\n",
    "(X3_train_std, y3_train, X3_test_std, y3_test) = set3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testowanie perceptronu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 0\n",
      "Accuracy: 1.00\n",
      "Misclassified samples: 7\n",
      "Accuracy: 0.77\n",
      "Misclassified samples: 1\n",
      "Accuracy: 0.97\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppn1 = Perceptron2(n_iter=100, eta=0.01, random_state=0)\n",
    "ppn2 = Perceptron2(n_iter=100, eta=0.01, random_state=0)\n",
    "ppn3 = Perceptron2(n_iter=100, eta=0.01, random_state=0)\n",
    "\n",
    "ppn1.fit(X1_train_std, y1_train)\n",
    "ppn2.fit(X2_train_std, y2_train)\n",
    "ppn3.fit(X3_train_std, y3_train)\n",
    "\n",
    "y1_pred = ppn1.predict(X1_test_std)\n",
    "y2_pred = ppn2.predict(X2_test_std)\n",
    "y3_pred = ppn3.predict(X3_test_std)\n",
    "\n",
    "print('Misclassified samples: %d' % (y1_test != y1_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y1_test, y1_pred))\n",
    "print('Misclassified samples: %d' % (y2_test != y2_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y2_test, y2_pred))\n",
    "print('Misclassified samples: %d' % (y3_test != y3_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y3_test, y3_pred))\n",
    "\n",
    "test_total_performance(X1_std, ppn1, ppn2, ppn3, yy1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testowanie Adaline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 19\n",
      "Accuracy: 0.37\n",
      "Misclassified samples: 17\n",
      "Accuracy: 0.43\n",
      "Misclassified samples: 24\n",
      "Accuracy: 0.20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta = 0.003\n",
    "n_iter = 100\n",
    "\n",
    "ada1 = Adaline(n_iter=n_iter, eta=eta, random_state=0)\n",
    "ada2 = Adaline(n_iter=n_iter, eta=eta, random_state=0)\n",
    "ada3 = Adaline(n_iter=n_iter, eta=eta, random_state=0)\n",
    "\n",
    "ada1.fit(X1_train_std, y1_train)\n",
    "ada2.fit(X2_train_std, y2_train)\n",
    "ada3.fit(X3_train_std, y3_train)\n",
    "\n",
    "y1_pred_a = ada1.predict(X1_test_std)\n",
    "y2_pred_a = ada2.predict(X2_test_std)\n",
    "y3_pred_a = ada3.predict(X3_test_std)\n",
    "\n",
    "print('Misclassified samples: %d' % (y1_test != y1_pred_a).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y1_test, y1_pred_a))\n",
    "print('Misclassified samples: %d' % (y2_test != y2_pred_a).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y2_test, y2_pred_a))\n",
    "print('Misclassified samples: %d' % (y3_test != y3_pred_a).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y3_test, y3_pred_a))\n",
    "\n",
    "test_total_performance(X1_std, ada1, ada2, ada3, yy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
